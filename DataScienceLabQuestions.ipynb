{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl7WzrXhbulQ0XQu/ZovpP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azmisaud/MCALab3/blob/main/DataScienceLabQuestions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week11 Question5"
      ],
      "metadata": {
        "id": "Q5ZMfXnsAIxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating the demo dataset."
      ],
      "metadata": {
        "id": "4UjWLkvIA9dd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_hSUQoBACPy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples=1000\n",
        "\n",
        "x1=np.random.choice(['A','B','C','D'],num_samples)\n",
        "x2=np.random.choice(['W','X','Y','Z'],num_samples)\n",
        "\n",
        "x3=np.random.normal(loc=50,scale=10,size=num_samples)\n",
        "x4=np.random.uniform(0,100,size=num_samples)\n",
        "x5=np.random.normal(loc=30,scale=5,size=num_samples)\n",
        "x6=np.random.uniform(10,50,size=num_samples)\n",
        "x7=np.random.uniform(0,1,size=num_samples)\n",
        "\n",
        "y=np.random.choice([0,1],num_samples)\n",
        "\n",
        "data=pd.DataFrame({\n",
        "    'x1':x1,\n",
        "    'x2':x2,\n",
        "    'x3':x3,\n",
        "    'x4':x4,\n",
        "    'x5':x5,\n",
        "    'x6':x6,\n",
        "    'x7':x7,\n",
        "    'y':y\n",
        "})\n",
        "\n",
        "data.to_csv('demo_dataset.csv',index=False)\n",
        "\n",
        "print(\"Dataset generated and saved as demo.csv\")"
      ],
      "metadata": {
        "id": "NskhSV--BWLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the generated dataset"
      ],
      "metadata": {
        "id": "L0QgFeFGEmqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df=pd.read_csv('demo_dataset.csv')"
      ],
      "metadata": {
        "id": "mBNOJmPuEpQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the data"
      ],
      "metadata": {
        "id": "WhZ21GduEG3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "TO2U0A0dEQqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values=data_df.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "#There are no missing values since the data is generated as per the choice."
      ],
      "metadata": {
        "id": "0aR2PFFkEKBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Outliers"
      ],
      "metadata": {
        "id": "XDVmyjwuFWsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the IQR method for outlier handling\n",
        "for col in ['x3','x4','x5','x6']:\n",
        "  Q1=data_df[col].quantile(0.25)\n",
        "  Q3=data_df[col].quantile(0.75)\n",
        "  IQR=Q3-Q1\n",
        "  lower_bound=Q1-1.5*IQR\n",
        "  upper_bound=Q3+1.5*IQR\n",
        "  data_df[col]=np.where(data_df[col]<lower_bound,lower_bound,data_df[col])\n",
        "  data_df[col]=np.where(data_df[col]>upper_bound,upper_bound,data_df[col])"
      ],
      "metadata": {
        "id": "XKKLrgJVFZiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encoding the nominal data"
      ],
      "metadata": {
        "id": "F1Sz0-lJHa0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the LabelEncoder from sklearn"
      ],
      "metadata": {
        "id": "db8p-QE2Heo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "p74xWNj4Hjtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder=LabelEncoder()\n",
        "\n",
        "data_df['x1']=label_encoder.fit_transform(data_df['x1'])\n",
        "data_df['x2']=label_encoder.fit_transform(data_df['x2'])"
      ],
      "metadata": {
        "id": "HRe-fCI7Ho3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling the data"
      ],
      "metadata": {
        "id": "3mHttWdvIQZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the standard scaler from sklearn"
      ],
      "metadata": {
        "id": "_BV22ymoIWf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "leIpHhdMIU0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=data_df.drop(columns=['y'])\n",
        "y=data_df['y']\n",
        "\n",
        "continous_features=['x3','x4','x5','x6']\n",
        "\n",
        "scaler=StandardScaler()\n",
        "\n",
        "X_scaled=X.copy()\n",
        "X_scaled[continous_features]=scaler.fit_transform(X[continous_features])\n",
        "\n",
        "X_scaled['x7']=X['x7']\n",
        "\n",
        "final_df=pd.concat([X_scaled, y.reset_index(drop=True)],axis=1)"
      ],
      "metadata": {
        "id": "V8ZEy788IjVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training this dataset"
      ],
      "metadata": {
        "id": "BYvaGzGKLjpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the libraries"
      ],
      "metadata": {
        "id": "VDPDEg-7LrUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zqMxPP_zLqlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=final_df.drop(columns=['y'])\n",
        "y=final_df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n"
      ],
      "metadata": {
        "id": "thsQErszMFe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "Vh9mqA-aLnMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg=LogisticRegression(random_state=42)\n",
        "\n",
        "log_reg.fit(X_train,y_train)\n",
        "\n",
        "y_pred=log_reg.predict(X_test)\n",
        "\n",
        "accuracy_reg=accuracy_score(y_test,y_pred)\n",
        "f1_reg=f1_score(y_test,y_pred)\n",
        "conf_matrix_reg=confusion_matrix(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy:\",accuracy_reg)\n",
        "print(\"F1 Score:\",f1_reg)\n",
        "print(\"Confusion Matrix :\\n \", conf_matrix_reg)"
      ],
      "metadata": {
        "id": "X7HmjaEYMtJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "v7wRq8QNNyBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "decision_tree.fit(X_train,y_train)\n",
        "\n",
        "y_pred_dt=decision_tree.predict(X_test)\n",
        "\n",
        "accuracy_dt=accuracy_score(y_test,y_pred_dt)\n",
        "f1_dt=f1_score(y_test,y_pred_dt)\n",
        "conf_matrix_dt=confusion_matrix(y_test,y_pred_dt)\n",
        "\n",
        "print(\"Accuracy:\",accuracy_dt)\n",
        "print(\"F1 Score:\",f1_dt)\n",
        "print(\"Confusion Matrix : \\n\", conf_matrix_dt)"
      ],
      "metadata": {
        "id": "jESHuS_-OFs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "YtX8QyynOtdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest=RandomForestClassifier(random_state=42)\n",
        "\n",
        "random_forest.fit(X_train,y_train)\n",
        "\n",
        "y_pred_rf=random_forest.predict(X_test)\n",
        "\n",
        "accuracy_rf=accuracy_score(y_test,y_pred_rf)\n",
        "f1_rf=f1_score(y_test,y_pred_rf)\n",
        "conf_matrix_rf=confusion_matrix(y_test,y_pred_rf)\n",
        "\n",
        "print(\"Accuracy:\",accuracy_rf)\n",
        "print(\"F1 Score:\",f1_rf)\n",
        "print(\"Confusion Matrix : \\n\", conf_matrix_rf)"
      ],
      "metadata": {
        "id": "zo2QE76SOz6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week12 Question5"
      ],
      "metadata": {
        "id": "4jYZzYp-cNPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "-jIM0DjRcQyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the random values of independent variables and constant."
      ],
      "metadata": {
        "id": "hiFs1CSyciiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "x1=np.random.rand(1000)\n",
        "x2=np.random.rand(1000)\n",
        "c=np.random.rand(1000)"
      ],
      "metadata": {
        "id": "91BV3U98clC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the dependent variable."
      ],
      "metadata": {
        "id": "pxbSLXQjc5KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=x1**2+3*x2+c"
      ],
      "metadata": {
        "id": "Aelr0g1mc-iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining x1 and x2 in a 2D array."
      ],
      "metadata": {
        "id": "9U_9VmYndEuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.column_stack((x1,x2))"
      ],
      "metadata": {
        "id": "h1i2asaCdIJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Polynomial features to train."
      ],
      "metadata": {
        "id": "koU8Ep0QdgG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "jHdphlY1dmXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly=PolynomialFeatures(degree=2)\n",
        "X_poly=poly.fit_transform(X)"
      ],
      "metadata": {
        "id": "RJ94-mc8dtPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_poly has 6 columns [1,x1,x2,x1^2,x1*x2,x2^2]\n"
      ],
      "metadata": {
        "id": "fUN4Lyq9eIHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Dataset into Training and Testing Sets"
      ],
      "metadata": {
        "id": "n_rIHEoTeNtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "09JLDNR8eJ6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X_poly,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "3OSUrI_SeeMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "b29FMshnevtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "D21rpZ3Aexix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=LinearRegression()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred=model.predict(X_test)"
      ],
      "metadata": {
        "id": "dR9xhmrxe2YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Evaluation Metrics"
      ],
      "metadata": {
        "id": "pw5FcOnufeaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "aK8Q6yySfo_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2=r2_score(y_test,y_pred)\n",
        "print(\"R2 Score:\",r2)"
      ],
      "metadata": {
        "id": "Wzo-97UwfhmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae=mean_absolute_error(y_test,y_pred)\n",
        "print(\"Mean Absolute Error:\",mae)"
      ],
      "metadata": {
        "id": "fGcyHolKfyNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse=mean_squared_error(y_test,y_pred)\n",
        "print(\"Mean Squared Error:\",mse)"
      ],
      "metadata": {
        "id": "FNcAqCqLf2LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week13 Question5"
      ],
      "metadata": {
        "id": "7rhQ2Kz6hJkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "SF_21lOBhNIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the MNIST dataset"
      ],
      "metadata": {
        "id": "9jsTpj4ghwQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train), (x_test,y_test)=datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "_1o1zCSahyT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the data"
      ],
      "metadata": {
        "id": "WwqKgVUgh-JM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the images to values between 0 and 1"
      ],
      "metadata": {
        "id": "FVH20uzriEKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.astype('float32')/255.0\n",
        "x_test=x_test.astype('float32')/255.0"
      ],
      "metadata": {
        "id": "6vQXaYrriIvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting labels to binary"
      ],
      "metadata": {
        "id": "soGLw_S0jI-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_binary=np.where(y_train==8,1,0)\n",
        "y_test_binary=np.where(y_test==8,1,0)"
      ],
      "metadata": {
        "id": "_3KzqEpLjMQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping data to add channel dimension"
      ],
      "metadata": {
        "id": "GzbabzJjjX6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape((x_train.shape[0],28,28,1))\n",
        "x_test=x_test.reshape((x_test.shape[0],28,28,1))"
      ],
      "metadata": {
        "id": "Jq2WY6Z4jbri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the CNN model"
      ],
      "metadata": {
        "id": "4r9_hKG8jkn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn=models.Sequential([\n",
        "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64,activation='relu'),\n",
        "    layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "6Yyxy79zjriK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "2dHhtO7OklHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "19Y6LZCpknnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "HC0q6536k3Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.fit(x_train,y_train_binary,epochs=5,batch_size=64,validation_split=0.2)"
      ],
      "metadata": {
        "id": "xevXQKMVk5BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "dQf0_E-wmGe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc=model_cnn.evaluate(x_test,y_test_binary)\n",
        "print(\"Test Accuracy:\",test_acc)"
      ],
      "metadata": {
        "id": "eUKQFcPemJmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=(model_cnn.predict(x_test)>0.5).astype('int32')"
      ],
      "metadata": {
        "id": "_h2d008XmREd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test_binary,y_pred))\n",
        "print(classification_report(y_test_binary,y_pred))"
      ],
      "metadata": {
        "id": "7Ck4TA6ImdQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week14 Question5"
      ],
      "metadata": {
        "id": "PWhi1TdVKT31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wwlNR1BVKdTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating the dataset"
      ],
      "metadata": {
        "id": "r5b8CNOeKaVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "x1=np.random.normal(0,1,1000)\n",
        "x2=np.random.normal(1,2,1000)\n",
        "x3=np.random.normal(2,1,1000)\n",
        "x4=np.random.normal(3,1.5,1000)\n",
        "\n",
        "#Introducing Outliers\n",
        "x1[::50]=x1[::50]+np.random.normal(10,5,20)\n",
        "x2[::50]=x2[::50]-np.random.normal(10,5,20)\n",
        "\n",
        "x5=np.random.choice(['A','B','C','D'],1000)\n",
        "\n",
        "y=(x1+x2+np.random.normal(0,0.5,1000)>1).astype(int)\n",
        "\n",
        "w14_q5_data=pd.DataFrame({\n",
        "    'x1':x1,\n",
        "    'x2':x2,\n",
        "    'x3':x3,\n",
        "    'x4':x4,\n",
        "    'x5':x5,\n",
        "    'y':y\n",
        "})\n",
        "\n",
        "missing_indices_x1=np.random.choice(w14_q5_data.index,size=30,replace=False)\n",
        "missing_indices_x3=np.random.choice(w14_q5_data.index,size=20,replace=False)\n",
        "\n",
        "w14_q5_data.loc[missing_indices_x1,'x1']=np.nan\n",
        "w14_q5_data.loc[missing_indices_x3,'x3']=np.nan\n",
        "\n",
        "w14_q5_data.to_csv('w14_q5_data.csv',index=False)"
      ],
      "metadata": {
        "id": "ZuHlx-ANKXL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the dataset"
      ],
      "metadata": {
        "id": "fJZaAIvHL8Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w14_q5_data=pd.read_csv('w14_q5_data.csv')"
      ],
      "metadata": {
        "id": "tSyheTuCL_dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling missing values"
      ],
      "metadata": {
        "id": "ZDd6ex59MDok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values before cleaning : \\n\", w14_q5_data.isnull().sum())"
      ],
      "metadata": {
        "id": "H4todZVKMNb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing values with median\n",
        "w14_q5_data['x1'].fillna(w14_q5_data['x1'].median(), inplace=True)\n",
        "w14_q5_data['x3'].fillna(w14_q5_data['x3'].median(), inplace=True)"
      ],
      "metadata": {
        "id": "sgrFjAsjMhCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values after cleaning : \\n\", w14_q5_data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "hNb-bBGHM9a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Outliers"
      ],
      "metadata": {
        "id": "6nKmBiCeNVi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to cap outliers based on the IQR method.\n",
        "\n",
        "def cap_outliers(df,column):\n",
        "  Q1=df[column].quantile(0.25)\n",
        "  Q3=df[column].quantile(0.75)\n",
        "  IQR=Q3-Q1\n",
        "  lower_bound=Q1-1.5*IQR\n",
        "  upper_bound=Q3+1.5*IQR\n",
        "  df[column]=np.where(df[column]<lower_bound,lower_bound,df[column])\n",
        "  df[column]=np.where(df[column]>upper_bound,upper_bound,df[column])"
      ],
      "metadata": {
        "id": "mtmDFeylNepV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap_outliers(w14_q5_data,'x1')\n",
        "cap_outliers(w14_q5_data,'x2')"
      ],
      "metadata": {
        "id": "iNfFgGZUODCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the Nominal Features using one-hot encoding"
      ],
      "metadata": {
        "id": "CGjVvq_fOYFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w14_q5_data=pd.get_dummies(w14_q5_data,columns=['x5'],drop_first=False)"
      ],
      "metadata": {
        "id": "Kcl8mILZOTA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w14_q5_data.head(4)"
      ],
      "metadata": {
        "id": "_0Hsd7seOjTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the cleaned data"
      ],
      "metadata": {
        "id": "OIpUtyA9Oy-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w14_q5_data.to_csv('w14_q5_data_cleaned.csv',index=False)"
      ],
      "metadata": {
        "id": "lg0UawqiO00W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heatmap to show correlations among independent features"
      ],
      "metadata": {
        "id": "Z0N9LhidPEjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7sKihjyZPKWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data=pd.read_csv(\"w14_q5_data_cleaned.csv\")"
      ],
      "metadata": {
        "id": "EiCfFXanPQAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent_features=cleaned_data[['x1','x2','x3','x4','x5_A','x5_B','x5_C','x5_D']]\n",
        "correlation_matrix=independent_features.corr()"
      ],
      "metadata": {
        "id": "zuyQGT3ePYJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(correlation_matrix,annot=True,cmap='coolwarm',linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IvRgu6SDQSU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the dataset"
      ],
      "metadata": {
        "id": "BxMnEA_TQmV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "HzldxwF5QtLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=cleaned_data.drop(columns=['y'])\n",
        "y=cleaned_data['y']\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "p-Z7iG7jRHwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "8eMgPr1uQpHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "laQYxQI3RCCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg=LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train,y_train)\n",
        "y_pred_lg=log_reg.predict(X_test)\n",
        "\n",
        "accuracy_lg=accuracy_score(y_test,y_pred_lg)\n",
        "f1_lg=f1_score(y_test,y_pred_lg)\n",
        "\n",
        "print(\"Accuracy:\",accuracy_lg)\n",
        "print(\"F1 Score:\",f1_lg)"
      ],
      "metadata": {
        "id": "Cejo8K6aREKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "5mrH9PkYRnTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "fIjyDPjPRp85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train,y_train)\n",
        "y_pred_dt=decision_tree.predict(X_test)\n",
        "\n",
        "accuracy_dt=accuracy_score(y_test,y_pred_dt)\n",
        "f1_dt=f1_score(y_test,y_pred_dt)\n",
        "\n",
        "print(\"Accuracy:\",accuracy_dt)\n",
        "print(\"F1 Score:\",f1_dt)"
      ],
      "metadata": {
        "id": "FL5vc8qGRvJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "3Vnl-wSzSD9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "Y3XGhcUzSGSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest=RandomForestClassifier(random_state=42)\n",
        "random_forest.fit(X_train,y_train)\n",
        "y_pred_rf=random_forest.predict(X_test)\n",
        "\n",
        "accuracy_rf=accuracy_score(y_test,y_pred_rf)\n",
        "f1_rf=f1_score(y_test,y_pred_rf)\n",
        "\n",
        "print(\"Accuracy:\",accuracy_rf)\n",
        "print(\"F1 Score:\",f1_rf)"
      ],
      "metadata": {
        "id": "GuzWNt1aSJLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting confusion matrix"
      ],
      "metadata": {
        "id": "HHltJuzrSpr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "znuTR_EsSws6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_true,y_pred,model_name):\n",
        "  cm=confusion_matrix(y_true,y_pred)\n",
        "  plt.figure(figsize=(8,6))\n",
        "  sns.heatmap(cm,annot=True,fmt='d',cmap='Blues',\n",
        "              xticklabels=['Predicted 0','Predicted 1'],\n",
        "              yticklabels=['Actual 0','Actual 1'])\n",
        "  plt.title(f'Confusion Matrix - {model_name}')\n",
        "  plt.xlabel('Predicted Labels')\n",
        "  plt.ylabel('True Labels')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "AjpxTKi1SuJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "plot_confusion_matrix(y_test,y_pred_lg,'Logistic Regression')"
      ],
      "metadata": {
        "id": "Vv_TzJrlTYyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "plot_confusion_matrix(y_test,y_pred_dt,'Decision Tree')"
      ],
      "metadata": {
        "id": "olguqroGTmHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "plot_confusion_matrix(y_test,y_pred_rf,'Random Forest')"
      ],
      "metadata": {
        "id": "nrmP604LTvDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week14 Question6"
      ],
      "metadata": {
        "id": "i8ERkIjFnaqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "5vc1tv9ened7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.random.rand(1000)\n",
        "k=np.random.rand(1000)\n",
        "\n",
        "y=3*x+k"
      ],
      "metadata": {
        "id": "4rfaCMCXnhqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test_w14=train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "lZ4p-WkUoHyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w14_q6_model=LinearRegression()\n",
        "w14_q6_model.fit(X_train.reshape(-1,1),y_train)\n",
        "\n",
        "y_pred_w14=w14_q6_model.predict(X_test.reshape(-1,1))\n",
        "\n",
        "mse_w14=mean_squared_error(y_test_w14,y_pred_w14)\n",
        "print(mse_w14)"
      ],
      "metadata": {
        "id": "g4SpmCt5oOl3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}